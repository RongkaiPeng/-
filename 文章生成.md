# 文章生成方面

## 0.传统dataToText的方法

**第一步：内容确定 - Content Determination**

NLG 系统需要决定哪些信息应该包含在正在构建的文本中，哪些不应该包含。通常数据中包含的信息比最终传达的信息要多。

**第二步：文本结构 - Text Structuring**

确定需要传达哪些信息后，NLG 系统需要合理的组织文本的顺序。例如在报道一场篮球比赛时，会优先表达「什么时间」「什么地点」「哪2支球队」，然后再表达「比赛的概况」，最后表达「比赛的结局」。

**第三步：句子聚合 - Sentence Aggregation**

不是每一条信息都需要一个独立的句子来表达，将多个信息合并到一个句子里表达可能会更加流畅，也更易于阅读。

**第四步：语法化 - Lexicalisation**

当每一句的内容确定下来后，就可以将这些信息组织成自然语言了。这个步骤会在各种信息之间加一些连接词，看起来更像是一个完整的句子。

**第五步：参考表达式生成 - Referring Expression Generation|REG**

这个步骤跟语法化很相似，都是选择一些单词和短语来构成一个完整的句子。不过他跟语法化的本质区别在于REG需要识别出内容的领域，然后使用该领域（而不是其他领域）的词汇”。

**第六步：语言实现 - Linguistic Realisation**

最后，当所有相关的单词和短语都已经确定时，需要将它们组合起来形成一个结构良好的完整句子。

## 1.目前各大公司、研究院的文章生成解决方案

### 百度：

> https://ai.baidu.com/creation/external/editproject/66001
>
> https://ai.baidu.com/ai-doc/NLP/ik3hbjj0v

要求有结构化的信息，自己写模板；对于提供的数据，根据小量的运算之后得出一些已经编译好的模板（根据实际情况显示预存模板）；同义模板的替换

### 腾讯：

<img src="C:\Users\q1171\Desktop\每天的学习\图片\image-20201104165441416.png" alt="image-20201104165441416" style="zoom:50%;" />

<img src="C:\Users\q1171\Desktop\每天的学习\图片\image-20201104165503744.png" alt="image-20201104165503744" style="zoom:50%;" />

<img src="C:\Users\q1171\Desktop\每天的学习\图片\image-20201104165556471.png" alt="image-20201104165556471" style="zoom:50%;" />

是由可以明显看出的结构化语言形成的，在生成的文章出，出现的参数，则有对应的参数显示的方案（根据关键词说话）（这需要很多规则）

### 华为：

华为nlp为收费api，且没有示例

**最近有的实现：**

==T5==：从数据生成文章，利用Google的T5模型，对WebNLG2020数据集（RDF-Text）的数据集生成任务，连接为：https://blog.csdn.net/weixin_26731327/article/details/109122652  但缺点是T5没有中文预训练的模型，T5的训练用了750G干净的英文数据，中文训练需要的代价过高，且t5只看到对应的短文本实现

T5大概的结果实现结果如下：

​          ![Image for post](https://img-blog.csdnimg.cn/img_convert/a3278ec381249c88c2e627fc4ef5684d.png)         RDF三元组

生成的文本：Trane, which was founded on January 1st, 1913 in La Crosse, Wisconsin, is based in Ireland. It has 29,000 employees.

==PHVM==：Long and Diverse Text Generation with Planning-based Hierarchical Variational Model 清华大学2019年论文，项目开源，使用tensorflow1.0构建，基于CVAE(条件变分自编码器)

https://github.com/ZhihongShao/Planning-based-Hierarchical-Variational-Model

其大概模型结构为：

<img src="C:\Users\q1171\Desktop\每天的学习\图片\image-20201110101056445.png" alt="image-20201110101056445"  />

其中，$d_i$为结构化数据，其具体构架为：<$a_i,v_i$>  ，最终的$S_i$为生成的句子，在论文中的生成的商品描述text为：

![image-20201110101355087](C:\Users\q1171\Desktop\每天的学习\图片\image-20201110101355087.png)

## 2.大概想法

如果是对于公司项目，如果$word_a、word_b、word_c$同时存在，则一起输出$sen_a、sen_b、sen_c$，这三个句子是连起来是完整的一句话，但如果只有$word_a word_b$，那可能就生成另外的$sen_d$，这一句中同时囊括$word_a word_b$的信息，这样我们就可以设置一个excel or csv文件，填入固定格式的数据，能根据==内部规则==生成文章，如果对应的数据缺失，则内部规则也能处理缺失部分的数据，更改语序，生成文章

对于内部规则应该怎么定义呢？

可以通过大量的文章学习关键句式，抽取其中关键词（也就是我们后期添加的结构式数据）所对应的句式，自动的去学习关键词对应的语句、甚至是联合关键词对应的语句

复现PHVM论文看看具体效果

## 3.数据集

WIKIBIO ROTOWIRE

## 4.评价指标

PHVM中的人工评价
$$
\frac{\sum a_i}{\sum P(a_i|b)}
$$
